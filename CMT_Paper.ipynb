{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xt_wAsmXzXR7",
        "outputId": "cd13051a-006d-4a4d-bae9-1c448d6d7629"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.5.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-25.7.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.16.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (1.6.1)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.12/dist-packages (from scikit-optimize) (25.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.12/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn>=1.0.0->scikit-optimize) (3.6.0)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-25.7.0-py3-none-any.whl (26 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-25.7.0 scikit-optimize-0.10.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Sn3hIEbyFaP",
        "outputId": "2f52e14a-c0cd-4482-e995-1cc412093a08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The starttime is : 29393639014.87099  Seconds\n"
          ]
        }
      ],
      "source": [
        "\"\"\" ******************************************************************************** \"\"\"\n",
        "import time\n",
        "start = time.time()\n",
        "print(\"The starttime is :\", (start) * 10**3/60, \" Seconds\")\n",
        "\"\"\" ******************************************************************************** \"\"\"\n",
        "import cv2\n",
        "import os, sys\n",
        "import shap\n",
        "import pandas            as pd\n",
        "import tensorflow        as tf\n",
        "import numpy             as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn           as sns\n",
        "from sklearn                       import metrics\n",
        "from sklearn.metrics               import accuracy_score, confusion_matrix,  classification_report, f1_score, roc_curve, roc_auc_score, ConfusionMatrixDisplay\n",
        "from sklearn.model_selection       import train_test_split\n",
        "from tensorflow.keras.regularizers import l1_l2\n",
        "from tensorflow.keras.utils        import to_categorical\n",
        "from keras.callbacks               import EarlyStopping\n",
        "from tensorflow.keras.models       import Sequential, Model\n",
        "from tensorflow.keras.layers       import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "from tensorflow.keras.applications import VGG16, ResNet50, MobileNetV2\n",
        "from tensorflow.keras.applications import InceptionResNetV2, InceptionV3\n",
        "from tensorflow.keras.applications import DenseNet201, Xception, EfficientNetB0\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.resnet50 import ResNet50, preprocess_input\n",
        "\n",
        "from sklearn.svm             import SVC\n",
        "from sklearn.preprocessing   import StandardScaler\n",
        "from sklearn.ensemble        import RandomForestClassifier\n",
        "from sklearn.tree            import DecisionTreeClassifier,  plot_tree\n",
        "from scipy.stats             import randint\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.datasets        import make_classification\n",
        "from sklearn.model_selection import KFold,cross_val_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from skopt                   import BayesSearchCV #pip install scikit-optimize\n",
        "from sklearn.neighbors       import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Configurations:\n",
        "\n",
        "  #All these parameter should be changed based on your dataset\n",
        "  Data_Path       = \"E:\\\\CMT Mammary Tumors\\\\Datasets\\\\CMT Dataset\\\\\"\n",
        "\n",
        "  model_path   = \"Best_Model_Weights.h5\"\n",
        "  CMT_labels   = ['benign', 'malignant']\n",
        "  CMT_values   = [0       ,     1      ]\n",
        "  Num_Classes  = len(CMT_labels)\n",
        "  CNN_Models   = ['Basic', 'VGG', 'ResNet50','MobileNet','InceptionResNet', 'Inception', 'Xception', 'EfficientNet', 'DenseNet201']\n",
        "  augments     = [True , False]\n",
        "\n",
        "  IMAGE_WIDTH  = 224 #128 224 256\n",
        "  IMAGE_HEIGHT = 224 #128 224 256\n",
        "  test_size    = 0.20\n",
        "  learning_rate= 0.001\n",
        "  batch_size   = 64\n",
        "  val_size     = 0.5 #50% of test as validate%\n",
        "  epochs       = 1\n",
        "  Current_CNN  = 'DenseNet201'\n",
        "\n",
        "  classifiers  = ['softmax', 'random_forest', 'svc', 'decision_tree', 'knn']\n",
        "  classifier   = 'knn'\n",
        "  augment      = False\n",
        "  patience     = 2\n",
        "\n",
        "  split_methods= ['splitNsamples', 'splittwice', 'splitfolders']\n",
        "  split_method = 'splittwice'\n",
        "\n",
        "  optimizeParam= False\n",
        "  optimizers   = ['RandomizedSearchCV' , 'GridSearchCV', 'BayesSearchCV']\n",
        "  optimizer    = 'RandomizedSearchCV'\n",
        "\n",
        "  def test_gpu(self):\n",
        "\n",
        "      print (\"Python version is     : \" , sys.version   )\n",
        "      print (\"tensorflow version is : \" , tf.__version__)\n",
        "\n",
        "      # Get detailed information about GPU(s)\n",
        "      gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "      if gpus:\n",
        "          print(\"\\nTensorFlow is using the following GPU(s):\")\n",
        "          for gpu in gpus:\n",
        "              print(gpu)\n",
        "      else:\n",
        "          print(\"\\nNo GPU detected or TensorFlow is not configured to use one.\")\n"
      ],
      "metadata": {
        "id": "-JNjFNtvzg0W"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CNN:\n",
        "\n",
        "  def One_Hot_Encoding(self, y_train, num_classes ):\n",
        "    y_train = to_categorical(y_train , num_classes=num_classes)\n",
        "    return y_train\n",
        "\n",
        "  def model_save(self, model , model_path):\n",
        "    model.save(model_path)\n",
        "\n",
        "  def plot_history(self, history):#call after model.fit\n",
        "\n",
        "      plt.figure(figsize=(12, 5))\n",
        "\n",
        "      # Plot loss\n",
        "      plt.subplot(1, 2, 1)\n",
        "      plt.plot(history.history['loss']    , label='train_loss')\n",
        "      plt.plot(history.history['val_loss'], label='val_loss')\n",
        "      plt.legend()\n",
        "      plt.xlabel('Epochs')\n",
        "      plt.ylabel('Loss')\n",
        "      plt.title('Loss over Epochs')\n",
        "\n",
        "      # Plot accuracy\n",
        "      plt.subplot(1, 2, 2)\n",
        "      plt.plot(history.history['accuracy']    , label='train_accuracy')\n",
        "      plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
        "      plt.legend()\n",
        "      plt.xlabel('Epochs')\n",
        "      plt.ylabel('Accuracy')\n",
        "      plt.title('Accuracy over Epochs')\n",
        "      plt.legend(loc='lower right')\n",
        "\n",
        "      plt.tight_layout()\n",
        "\n",
        "      # Save the figure\n",
        "      plt.savefig('Loss_accuracy.png', dpi=300, bbox_inches='tight')\n",
        "      #plt.show()\n",
        "\n",
        "  def plot_confusion_matrix(self, predictions, y_test):\n",
        "\n",
        "      y_pred                 = np.argmax(predictions, axis=1)  # Get the index of the maximum value\n",
        "      y_true                 = np.argmax(y_test, axis=1)\n",
        "      cm                     = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "      cmd                    = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "      cmd.plot(include_values= True, cmap='viridis', ax=None, xticks_rotation='horizontal')\n",
        "\n",
        "      # Save the figure\n",
        "      plt.savefig('Confusion Matrix.png', dpi=300, bbox_inches='tight')\n",
        "      #plt.show()\n",
        "\n",
        "  def plot_classification_report(self,  predictions, y_test , CMT_labels, Num_Classes):\n",
        "\n",
        "      predicted_classes = [np.argmax(pred) for pred in predictions]\n",
        "\n",
        "      classes           = CMT_labels\n",
        "      predicted_classes = self.One_Hot_Encoding(predicted_classes, Num_Classes)\n",
        "\n",
        "      print(classification_report(y_test, predicted_classes))\n",
        "\n",
        "      report            = classification_report(y_test, predicted_classes, target_names=classes, output_dict=True)\n",
        "      metrics           = {label: report[label]        for label in classes if label in report}\n",
        "      precision         = [metrics[label]['precision'] for label in classes]\n",
        "      recall            = [metrics[label]['recall']    for label in classes]\n",
        "      f1_score          = [metrics[label]['f1-score']  for label in classes]\n",
        "\n",
        "      data = {\n",
        "              'Precision': precision,\n",
        "              'Recall'   : recall,\n",
        "              'F1-Score' : f1_score\n",
        "              }\n",
        "\n",
        "      df   = pd.DataFrame(data, index=classes)\n",
        "\n",
        "      plt.figure(figsize=(10, 6))\n",
        "      sns.heatmap(df, annot=True, cmap='Blues', fmt=\".2f\", linewidths=0.5)\n",
        "      plt.title('Classification Report')\n",
        "      plt.xlabel('Metrics')\n",
        "      plt.ylabel('Classes')\n",
        "\n",
        "      # Save the figure\n",
        "      plt.savefig('Classification Report.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "      #plt.show()\n",
        "\n",
        "  def plot_predictions(self, predictions, x_test, y_test):\n",
        "\n",
        "    sample_classes = np.argmax(predictions, axis = 1)\n",
        "    sizeofplot     = 3 #subplot 3*3\n",
        "    fig, ax        = plt.subplots(sizeofplot,sizeofplot, figsize=(5,5))\n",
        "    index          = 0\n",
        "\n",
        "    for i in range(sizeofplot):\n",
        "        for j in range(sizeofplot):\n",
        "\n",
        "          if y_test[index].argmax() == 0:#argmax since one hot\n",
        "              true = \"benign\"\n",
        "          else:\n",
        "              true = \"malignant\"\n",
        "\n",
        "          if sample_classes[index] == 0:\n",
        "              pred = \"benign\"\n",
        "          else:\n",
        "              pred = \"malignant\"\n",
        "\n",
        "          color   = \"green\"\n",
        "          if true != pred:\n",
        "             color=\"red\"\n",
        "\n",
        "          ax[i][j].imshow(tf.squeeze(x_test[index]), cmap=plt.cm.gray)\n",
        "          ax[i][j].set_title(\"True: \" + true + \" Predicted: \"+ pred, color = color )\n",
        "          plt.axis(\"off\")\n",
        "          index = index + 1\n",
        "\n",
        "    # Save the figure\n",
        "    plt.savefig('Predictions.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "    fig.tight_layout()\n",
        "    #plt.show()\n",
        "    #cv2.waitKey(50)\n",
        "\n",
        "  def plot_auc(self, predictions, y_test ):\n",
        "\n",
        "    # Ensure that the target labels Y_test are in a 2-dimensional format\n",
        "    if len(y_test.shape) == 1:\n",
        "        y_test = np.eye(len(np.unique(y_test)))[y_test.astype(int)]\n",
        "\n",
        "    # Compute the ROC curve and AUC score for each class\n",
        "    fpr     = dict()\n",
        "    tpr     = dict()\n",
        "    roc_auc = dict()\n",
        "\n",
        "    for i in range(y_test.shape[1]):\n",
        "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], predictions[:, i])\n",
        "        roc_auc[i]        = roc_auc_score(y_test[:, i], predictions[:, i])\n",
        "\n",
        "    # Plot the ROC curve for each class\n",
        "    plt.figure()\n",
        "    for i in range(y_test.shape[1]):\n",
        "        plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
        "\n",
        "    # Set the title and axis labels\n",
        "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend(loc='lower right')\n",
        "\n",
        "    # Save the figure\n",
        "    plt.savefig('ROC.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "    # Show the plot\n",
        "    #plt.show()\n",
        "\n",
        "  def plot_auc_all(self, predictions, y_test):\n",
        "\n",
        "    plt.figure(0).clf()\n",
        "\n",
        "    pred  = np.random.rand(1000)\n",
        "    label = np.random.randint(2, size=1000)\n",
        "\n",
        "    fpr, tpr, thresh = metrics.roc_curve(label, pred)\n",
        "    auc   = metrics.roc_auc_score(label, pred)\n",
        "    plt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\n",
        "\n",
        "    pred  = np.random.rand(1000)\n",
        "    label = np.random.randint(2, size=1000)\n",
        "\n",
        "    fpr, tpr, thresh = metrics.roc_curve(label, pred)\n",
        "    auc   = metrics.roc_auc_score(label, pred)\n",
        "    plt.plot(fpr,tpr,label=\"data 2, auc=\"+str(auc))\n",
        "\n",
        "    plt.legend(loc=0)\n",
        "\n",
        "  def show_test_samples(self, test_path, pred_list, image_size):\n",
        "\n",
        "    index = 0\n",
        "    for item in os.listdir(test_path):\n",
        "\n",
        "      if index < 3 :\n",
        "          full_path  = test_path + item\n",
        "          img        = tf.keras.preprocessing.image.load_img(full_path, target_size=(image_size, image_size))\n",
        "          img_tensor = tf.keras.preprocessing.image.img_to_array(img)\n",
        "          img_tensor = np.expand_dims(img_tensor, axis=0)\n",
        "          img_tensor/= 255.\n",
        "          pred       = model.predict(img_tensor)\n",
        "          pred       = np.argmax(pred, axis = 1)[0]#model.predict(img_tensor)\n",
        "          pred_list.append([img, pred])\n",
        "\n",
        "          index = index+1\n",
        "\n",
        "    return pred_list\n",
        "\n",
        "  def plot_confusion_matrix_generator(self, predictions, y_test):\n",
        "\n",
        "    y_pred                 = np.argmax(predictions, axis=1)  # Get the index of the maximum value\n",
        "    cm                     = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "    cmd                    = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    cmd.plot(include_values= True, cmap='viridis', ax=None, xticks_rotation='horizontal')\n",
        "\n",
        "    # Save the figure\n",
        "    plt.savefig('Confusion Matrix.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "    #plt.show()\n",
        "\n",
        "  def evaluate_x_test(self, model, history , x_test, y_test, Num_Classes, CMT_labels, batch_size):\n",
        "\n",
        "    #1- Evaluate the model on the test data using `evaluate`\n",
        "    _, accuracy = model.evaluate(x_test, y_test, batch_size=batch_size)\n",
        "    print()\n",
        "    print('evaluation accuracy is**************************************************************:  %.3f' % (accuracy * 100.0))\n",
        "    print()\n",
        "\n",
        "    #2- Draw the results of accuray, and loss\n",
        "    self.plot_history(history)\n",
        "\n",
        "    #3- Make predictions softmax\n",
        "    y_pred  = model.predict(x_test)\n",
        "\n",
        "    #4- Plot the confusion matrix of this model for the test data\n",
        "    self.plot_confusion_matrix( y_pred, y_test)\n",
        "\n",
        "    #5- Plot the classification report of this model for the test data\n",
        "    self.plot_classification_report(y_pred, y_test, CMT_labels, Num_Classes)\n",
        "\n",
        "    #6- Show the predition results as images\n",
        "    #self.plot_predictions(y_pred , x_test, y_test)\n",
        "\n",
        "    #7- Plot AUC: area under the curve\n",
        "    self.plot_auc(y_pred, y_test)\n",
        "    #self.plot_auc_all( y_pred, y_test)\n",
        "\n",
        "  def evaluate_generator(self, model , history , test_generator, y_test, Num_Classes, CMT_labels, batch_size, image_size, test_path=\"\"):\n",
        "\n",
        "    #1- Evaluate the model on the test data using `evaluate`\n",
        "    _, accuracy = model.evaluate(test_generator, batch_size=batch_size)\n",
        "    print()\n",
        "    print('evaluation accuracy is**************************************************************:  %.3f' % (accuracy * 100.0))\n",
        "    print()\n",
        "\n",
        "    #2- Draw the results of accuray, and loss\n",
        "    self.plot_history(history)\n",
        "\n",
        "    #3-make the predictions of the model using the testing data\n",
        "    y_pred = model.predict(test_generator)\n",
        "\n",
        "    #4-Plot the confusion matrix\n",
        "    self.plot_confusion_matrix_generator(y_pred, y_test)\n",
        "\n",
        "    #5- Plot the classification report of this model for the test data\n",
        "    y_true                 = self.One_Hot_Encoding(y_test, Num_Classes)  # Get the index of the maximum value\n",
        "    self.plot_classification_report(y_pred, y_true, CMT_labels, Num_Classes)\n",
        "\n",
        "    #6- Plot AUC: area under the curve\n",
        "    self.plot_auc(y_pred, y_test)\n",
        "    #self.plot_auc_all( y_pred, y_test)\n"
      ],
      "metadata": {
        "id": "E_-yQ2B-zqf4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Models:\n",
        "\n",
        "  def CNN_Model(self, IMAGE_WIDTH, IMAGE_HEIGHT, Num_classes):\n",
        "    print (\"******************************************** Basic CNN Model *********************************************\")\n",
        "    model = Sequential()\n",
        "\n",
        "    # Input 0 of layer \"conv2d\" is incompatible with the layer: expected axis -1 of input shape to have value 1,\n",
        "    # but received input with shape (None, 128, 128, 3)\n",
        "    model.add(Conv2D(8, (3, 3), padding='same',activation='relu', input_shape=(IMAGE_WIDTH, IMAGE_HEIGHT, 3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(16, (3, 3), padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Conv2D(32, (3, 3), padding='same',activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "\n",
        "    model.add(Dropout(0.25))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "\n",
        "    return model\n",
        "\n",
        "  def VGG_Model(self, IMAGE_WIDTH, IMAGE_HEIGHT):\n",
        "      print (\"******************************************** VGG Model *********************************************\")\n",
        "      vgg       = VGG16(input_shape = (IMAGE_WIDTH, IMAGE_WIDTH , 3) , weights = 'imagenet', include_top = False)\n",
        "\n",
        "      return vgg\n",
        "\n",
        "  def ResNet_Model(self, IMAGE_WIDTH, IMAGE_HEIGHT):\n",
        "      print (\"******************************************** ResNet Model *********************************************\")\n",
        "      resnet    =  ResNet50(input_shape=(IMAGE_WIDTH,IMAGE_HEIGHT,3), weights = 'imagenet',include_top=False)\n",
        "      return resnet\n",
        "\n",
        "  def MobileNet(self, IMAGE_WIDTH, IMAGE_HEIGHT):\n",
        "      MobileNet = MobileNetV2      (input_shape = (IMAGE_WIDTH , IMAGE_HEIGHT ,3), weights = 'imagenet', include_top = False)\n",
        "      return MobileNet\n",
        "\n",
        "  def Inception_Model(self, IMAGE_WIDTH, IMAGE_HEIGHT):\n",
        "      print (\"******************************************** Inception Model *********************************************\")\n",
        "      inception = InceptionV3(input_shape = (IMAGE_WIDTH , IMAGE_HEIGHT ,3), weights = 'imagenet', include_top = False )\n",
        "      return inception\n",
        "\n",
        "  def InceptionResNet_Model(self, IMAGE_WIDTH, IMAGE_HEIGHT):\n",
        "      print (\"******************************************** InceptionResNet Model *********************************************\")\n",
        "      inceptionResnet = InceptionResNetV2(input_shape = (IMAGE_WIDTH , IMAGE_HEIGHT ,3), weights = 'imagenet', include_top = False )\n",
        "      return inceptionResnet\n",
        "\n",
        "  def DenseNet_Model(self, IMAGE_WIDTH , IMAGE_HEIGHT ):\n",
        "      print (\"******************************************** DenseNet Model *********************************************\")\n",
        "      DenseNet = DenseNet201(input_shape=(IMAGE_WIDTH , IMAGE_HEIGHT ,3), weights='imagenet', include_top=False, pooling='avg')\n",
        "      return DenseNet\n",
        "\n",
        "  def Exception_model(self, IMAGE_WIDTH, IMAGE_HEIGHT):\n",
        "      print (\"******************************************** Exception Model *********************************************\")\n",
        "      Exception = Xception(input_shape = (IMAGE_WIDTH , IMAGE_HEIGHT ,3), weights = 'imagenet', include_top = False )\n",
        "      return Exception\n",
        "\n",
        "  def EfficientNet_Model(self, IMAGE_WIDTH, IMAGE_HEIGHT):\n",
        "      print (\"******************************************** EfficientNet Model *********************************************\")\n",
        "      EfficientNet = EfficientNetB0(input_shape = (IMAGE_WIDTH , IMAGE_HEIGHT ,3), weights = 'imagenet', include_top = False )\n",
        "      return EfficientNet\n",
        "\n",
        "  def create_softmax_classifier(self, model, num_classes):\n",
        "\n",
        "      for layer in model.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "      x     = Flatten()(model.output)\n",
        "      x     = Dense(num_classes, activation = 'softmax')(x)\n",
        "      model = Model(inputs = model.input, outputs = x)\n",
        "\n",
        "      model.compile(optimizer= 'Adam',loss = 'categorical_crossentropy',metrics  = ['accuracy'])\n",
        "      return model\n",
        "\n",
        "  def create_svm_classifier(self, model, num_classes):\n",
        "\n",
        "      for layer in model.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "      x     = Flatten()(model.output)\n",
        "      x     = Dense(num_classes, activation='softmax', kernel_regularizer=l1_l2(l1=0.01, l2=0.01))(x)\n",
        "      model = Model(inputs = model.input, outputs = x)\n",
        "\n",
        "      model.compile(optimizer ='Adam', loss = 'squared_hinge', metrics  = ['accuracy'])\n",
        "      #model.summary()\n",
        "      return model\n",
        "\n",
        "  def choose_Model(self, Current_CNN, IMAGE_WIDTH, IMAGE_HEIGHT, Num_Classes, classifier):\n",
        "\n",
        "    if Current_CNN == 'Basic':\n",
        "        model = self.CNN_Model(IMAGE_WIDTH, IMAGE_HEIGHT, Num_Classes)\n",
        "\n",
        "    elif Current_CNN == 'VGG':\n",
        "        model = self.VGG_Model(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "\n",
        "    elif Current_CNN == 'ResNet50':\n",
        "        model = self.ResNet_Model(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "\n",
        "    elif Current_CNN == 'MobileNet':\n",
        "        model = self.MobileNet(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "\n",
        "    elif Current_CNN == 'Inception':\n",
        "        model = self.Inception_Model(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "\n",
        "    elif Current_CNN == 'InceptionResNet':\n",
        "        model = self.InceptionResNet_Model(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "\n",
        "    elif Current_CNN == 'DenseNet201':\n",
        "        model = self.DenseNet_Model(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "\n",
        "    elif Current_CNN == 'Xception':\n",
        "        model = self.Exception_model(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "\n",
        "    elif Current_CNN == 'EfficientNet':\n",
        "      model = self.EfficientNet_Model(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "\n",
        "    return model\n",
        "\n",
        "  def choose_classifier(self,  x_train, y_train, x_test, y_test, classifier, IMAGE_WIDTH, IMAGE_HEIGHT, optimize, optimizer, CMT_labels, Num_Classes):\n",
        "\n",
        "    model = Models.DenseNet_Model(IMAGE_WIDTH, IMAGE_HEIGHT)\n",
        "    for layer in model.layers:\n",
        "            layer.trainable = False\n",
        "\n",
        "    train_features  = model.predict(x_train)\n",
        "    train_features  = train_features.reshape(train_features.shape[0], -1)\n",
        "\n",
        "    test_features   = model.predict(x_test)\n",
        "    test_features   = test_features.reshape(test_features.shape[0], -1)\n",
        "\n",
        "    if classifier == \"svc\":\n",
        "        rf_model       = SVC()\n",
        "\n",
        "    elif classifier == \"decision_tree\":\n",
        "        rf_model       = DecisionTreeClassifier()\n",
        "\n",
        "    elif classifier==\"random_forest\":\n",
        "\n",
        "      if optimize:\n",
        "\n",
        "        param_dist  = {\n",
        "                        'n_estimators': [40, 50, 80, 100]\n",
        "                      }\n",
        "\n",
        "        if optimizer == 'RandomizedSearchCV':\n",
        "          rf_model = RandomizedSearchCV(rf_model, param_dist)\n",
        "\n",
        "        elif optimizer=='GridSearchCV':\n",
        "          rf_model = GridSearchCV( rf_model,   param_dist)\n",
        "\n",
        "        elif optimizer=='knn':\n",
        "          rf_model = KNeighborsClassifier( rf_model,   param_dist)\n",
        "\n",
        "        elif optimizer =='BayesSearchCV':\n",
        "          rf_model = BayesSearchCV( rf_model, param_dist)\n",
        "\n",
        "      else:\n",
        "        rf_model       = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "\n",
        "    rf_model.fit(train_features, y_train)\n",
        "    y_pred         = rf_model.predict(test_features)\n",
        "\n",
        "    print(\"accuracy  : \",    accuracy_score  (y_test, y_pred) )\n",
        "    print (\"f1-score : \",    f1_score        (y_test, y_pred  , average='macro'))\n",
        "    cm                     = confusion_matrix(y_test, y_pred)\n",
        "    cmd                    = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
        "    cmd.plot(include_values= True, cmap='viridis', ax=None, xticks_rotation='horizontal')\n",
        "    plt.savefig('Confusion Matrix.png', dpi=300, bbox_inches='tight')\n",
        "    #plt.show()\n",
        "\n",
        "    self.plot_classification_report(y_pred, y_test , CMT_labels, Num_Classes)\n"
      ],
      "metadata": {
        "id": "skICHdOAyaY9"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Data:\n",
        "\n",
        "  def Load_preprocess_resize_scale(self, Data_Path, IMAGE_WIDTH, IMAGE_HEIGHT, ClassLabel1):\n",
        "\n",
        "    # Download the training and validation data\n",
        "    filenames  = os.listdir(Data_Path) #Contains two folder one for images of each class\n",
        "    print(\"Folder Names = Class Labels: : \" , filenames)\n",
        "\n",
        "    Labels     = []\n",
        "    data       = []\n",
        "\n",
        "    for filename in filenames:\n",
        "\n",
        "      images = os.listdir(Data_Path + filename)\n",
        "\n",
        "      for image in images:\n",
        "        image_path = Data_Path + \"\\\\\"+ filename +\"\\\\\"+image\n",
        "\n",
        "        #Create Labels:\n",
        "        Label  = filename\n",
        "        if Label == ClassLabel1:\n",
        "          Label = 0 #Put 0  for benign\n",
        "        else:\n",
        "          Label = 1 #Put 1  for malignant\n",
        "\n",
        "        #Create Image\n",
        "        image = cv2.imread(image_path)\n",
        "\n",
        "        image = self.preprocess_sharpen(image)\n",
        "\n",
        "        #Resize image into 128*128\n",
        "        image = cv2.resize(image, (IMAGE_WIDTH , IMAGE_HEIGHT),interpolation = cv2.INTER_AREA)\n",
        "        #image = resize(image, (IMAGE_WIDTH , IMAGE_HEIGHT,1))\n",
        "\n",
        "        #print (\"when using SHAP, Comment this line since it affects it working properly ... \")\n",
        "        #Normalize image pixel values between 0 and 255.\n",
        "        image = image.astype('float') / 255.0\n",
        "\n",
        "        #Append both image, and labels in data array\n",
        "        data.append([image, Label])\n",
        "\n",
        "    print(\"Number of samples from both classes are: len (data)\" , len(data))\n",
        "\n",
        "    return data\n",
        "\n",
        "  def preprocess_sharpen(self, image):\n",
        "\n",
        "    kernel      = np.array([[0, -1, 0],\n",
        "                            [-1, 5,-1],\n",
        "                            [0, -1, 0]])\n",
        "\n",
        "    image = cv2.filter2D(src=image, ddepth=-1, kernel=kernel)\n",
        "\n",
        "    return image\n",
        "\n",
        "  def plot_label_count(self, data, CMT_labels):\n",
        "\n",
        "    #Plot count of label of each class in the dataset\n",
        "    labels         = np.array([i[1] for i in data])\n",
        "    elements_count = {}\n",
        "\n",
        "    for element in labels:\n",
        "      if element in elements_count:\n",
        "          elements_count[element] += 1\n",
        "      else:\n",
        "          elements_count[element] = 1\n",
        "\n",
        "    for key, value in elements_count.items():\n",
        "      print(f\"{key}: {value}\")\n",
        "\n",
        "    x = [CMT_labels[0]    , CMT_labels[1]]\n",
        "    y = [elements_count[0], elements_count[1]]\n",
        "\n",
        "    #sns.countplot(x='labels', data=y)\n",
        "\n",
        "    for i in range(len(x)):\n",
        "        plt.text(i, y[i]//2,y[i], ha = 'center')\n",
        "\n",
        "    plt.bar(x, y, color = 'red')\n",
        "    plt.title(\"The count of Each class in CMT dataset\")\n",
        "    plt.xlabel(\"CMT Classes\")\n",
        "    plt.ylabel(\"Count of Each Class\")\n",
        "    #plt.show()\n",
        "\n",
        "  def plot_data_samples3(self, x_train, y_train , label_name, label_value, sizeofplot):\n",
        "\n",
        "      fig, ax  = plt.subplots(sizeofplot,sizeofplot, figsize=(5,5))\n",
        "      result   = np.where(y_train[0:30] == label_value)[0]\n",
        "      index    = 0\n",
        "      for i in range(sizeofplot):\n",
        "        for j in range (sizeofplot):\n",
        "            ax[i][j].imshow(tf.squeeze(x_train[result[index]]), cmap=plt.cm.gray)\n",
        "            ax[i][j].set_title(\"Class : \" + label_name)\n",
        "            plt.axis(\"off\")\n",
        "            index =  index+1\n",
        "      fig.tight_layout()\n",
        "      #plt.show()\n",
        "\n",
        "  def plot_samples_path(self, Data_Path, dataset_name, label_name):\n",
        "\n",
        "    Data_Path = Data_Path + label_name+\"\\\\\"\n",
        "    images  = os.listdir(Data_Path) #Contains images of each class\n",
        "\n",
        "    index   = 0\n",
        "    size_fig= 2\n",
        "    fig, ax = plt.subplots(size_fig,size_fig, figsize=(5,5))\n",
        "    for i in range(size_fig):\n",
        "        for j in range (size_fig):\n",
        "            image = Data_Path+images[index]\n",
        "            image = cv2.imread(image)\n",
        "            #image = self.preprocess_sharpen(image)\n",
        "            ax[i][j].imshow(tf.squeeze(image), cmap=plt.cm.gray)\n",
        "            ax[i][j].set_title(\"Class : \" + label_name)\n",
        "            plt.axis(\"off\")\n",
        "            index =  index+1\n",
        "    #fig.tight_layout()\n",
        "    plt.savefig(dataset_name+' '+label_name+' Samples.png', dpi=300, bbox_inches='tight')\n",
        "    #plt.show()\n",
        "\n",
        "  def plot_label_count_path(self):\n",
        "\n",
        "    x = [\"benign\" , 'malignant', 'benign'    , 'malignant' ]\n",
        "    y = [480, 576, 576, 576]\n",
        "\n",
        "    #sns.countplot(x='labels', data=y)\n",
        "\n",
        "    for i in range(len(x)):\n",
        "        plt.text(i, y[i]//2,y[i], ha = 'center')\n",
        "\n",
        "    plt.bar(x, y, color = 'red')\n",
        "    plt.title(\"The count of Each class in CMT dataset\")\n",
        "    plt.xlabel(\"CMT Classes\")\n",
        "    plt.ylabel(\"Count of Each Class\")\n",
        "    plt.show()\n",
        "    plt.savefig('Balanced Labels.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "  def plot_counts_CMT_BreakHis(self):\n",
        "\n",
        "    blue_bar  = (480, 576, 2480, 5429)\n",
        "    orange_bar= (576, 576, 5429, 5429)\n",
        "\n",
        "    # Numbers of pairs of bars you want\n",
        "    N         = 4\n",
        "    ind       = np.arange(N)\n",
        "    width     = 0.3\n",
        "    plt.figure(figsize=(10,5))\n",
        "    plt.bar(ind,         blue_bar  , width, label='Unbalanced count')\n",
        "    plt.bar(ind + width, orange_bar, width, label='Balanced count', color='r')\n",
        "    plt.xlabel('CMT                                                                           BreakHis')\n",
        "    plt.ylabel('Number of samples in each class')\n",
        "    plt.title('Balancing number of samples in CMT and BreakHis Datasets')\n",
        "    plt.xticks(ind + width / 2, ('Benign', 'Malignant', 'Benign', 'Malignant'))\n",
        "    plt.legend(loc='best')\n",
        "    #plt.show()\n",
        "    #plt.savefig('Balanced Labels.png', dpi=300, bbox_inches='tight')\n",
        "    plt.savefig('Balancing Label counts.png', dpi=300, bbox_inches='tight')\n",
        "\n",
        "  def plot_all(self, Data_Path, dataset_name, x_train, y_train):\n",
        "\n",
        "    image_path   = Data_Path\n",
        "    dataset_name = \"CMT\"\n",
        "    self.plot_samples_path(Data_Path, dataset_name, \"benign\")\n",
        "    self.plot_samples_path(Data_Path, dataset_name, \"malignant\")\n",
        "    self.plot_counts_CMT_BreakHis()\n",
        "\n",
        "    #Plot samples of each class: benign and malignant\n",
        "    self.plot_data_samples3(x_train, y_train , 'benign'   , 0, 3) #Benign hs label 0\n",
        "    self.plot_data_samples3(x_train, y_train , 'malignant', 1, 3) #Malignant hs label 1\n",
        "\n",
        "  def split_train_test(self, data, test_size, IMAGE_WIDTH, IMAGE_HEIGHT):\n",
        "\n",
        "    X = np.array([i[0] for i in data]).reshape(-1, IMAGE_WIDTH, IMAGE_HEIGHT, 3)\n",
        "    y = np.array([i[1] for i in data])\n",
        "\n",
        "    x_train, x_test, y_train, y_test = train_test_split(X,y , test_size =test_size, shuffle = True, stratify=y, random_state=11)\n",
        "    print (\"x_train: \", x_train.shape)\n",
        "    print (\"y_train: \", y_train.shape)\n",
        "    print (\"x_test:  \", x_test.shape)\n",
        "    print (\"y_test:  \", y_test.shape)\n",
        "\n",
        "    return x_train, y_train, x_test, y_test\n",
        "\n",
        "  def split_test_val(self, x_test, y_test, val_size):\n",
        "\n",
        "      nsamples_val= int(val_size*len(x_test))\n",
        "      print (\"nsamples_val: \" , nsamples_val)\n",
        "\n",
        "      x_val = x_test[-nsamples_val:]\n",
        "      y_val = y_test[-nsamples_val:]\n",
        "\n",
        "      x_test = x_test[:-nsamples_val]\n",
        "      y_test = y_test[:-nsamples_val]\n",
        "\n",
        "      print (len(x_val))\n",
        "      print (len(y_val))\n",
        "      print (len(x_test))\n",
        "      print (len(x_test))\n",
        "\n",
        "      return x_test, y_test, x_val, y_val\n",
        "\n",
        "  def split_test_val_splittwice(self, x_test, y_test, val_size, IMAGE_WIDTH, IMAGE_HEIGHT):\n",
        "\n",
        "    new_data = []\n",
        "    for i in range(len(x_test)):\n",
        "        image = x_test[i]\n",
        "        label = y_test[i]\n",
        "        new_data.append([image, label])\n",
        "\n",
        "    X = np.array([i[0] for i in new_data]).reshape(-1, IMAGE_WIDTH, IMAGE_HEIGHT, 3)\n",
        "    y = np.array([i[1] for i in new_data])\n",
        "\n",
        "    x_test, x_val , y_test, y_val = train_test_split(X,y , test_size =val_size, shuffle = True, stratify=y, random_state=11)\n",
        "\n",
        "    print (\"x_val:  \", x_val.shape)\n",
        "    print (\"y_val:  \", y_val.shape)\n",
        "    print (\"x_test: \", x_test.shape)\n",
        "    print (\"y_test: \", y_test.shape)\n",
        "\n",
        "    return x_test, y_test, x_val, y_val\n",
        "\n",
        "  def Augment_x_train_flow(self, x_train, y_train, x_val, y_val, x_test, y_test,batch_size):\n",
        "\n",
        "      datagen                       = ImageDataGenerator( rotation_range = 5,width_shift_range = 0.01, height_shift_range= 0.01)\n",
        "\n",
        "      train_generator               = datagen.flow(x_train, y_train, batch_size = batch_size, seed= 42,save_prefix='',save_format='jpg')\n",
        "      validate_generator            = datagen.flow(x_val  , y_val  , batch_size = batch_size, seed= 42,save_prefix='',save_format='jpg')\n",
        "\n",
        "      test_gen                      = ImageDataGenerator(  ) #Image is already scaled and resize in load function\n",
        "      test_generator                = test_gen.flow( x_test,  y_test )\n",
        "\n",
        "      return train_generator, validate_generator, test_generator\n"
      ],
      "metadata": {
        "id": "cOV_n0av0CYx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "if __name__== '__main__':\n",
        "\n",
        "    Config  = Configurations()\n",
        "    Data    = Data()\n",
        "    CNN     = CNN()\n",
        "    Models  = Models()\n",
        "\n",
        "    #Config.test_gpu()\n",
        "\n",
        "    #Save images, and labels in array called data\n",
        "    data                            = Data.Load_preprocess_resize_scale(Config.Data_Path,Config.IMAGE_WIDTH, Config.IMAGE_HEIGHT, Config.CMT_labels[0])\n",
        "\n",
        "    #Split data into train and test with test_size ratio\n",
        "    x_train, y_train, x_test, y_test= Data.split_train_test(data, Config.test_size, Config.IMAGE_WIDTH,  Config.IMAGE_HEIGHT)\n",
        "\n",
        "    #Split test into val and test with test_size ratio\n",
        "    #x_test, y_test, x_val, y_val      = Data.split_test_val( x_test, y_test, Config.val_size)\n",
        "    x_test, y_test, x_val, y_val    = Data.split_test_val_splittwice( x_test, y_test, Config.val_size, Config.IMAGE_WIDTH, Config.IMAGE_HEIGHT)\n",
        "\n",
        "    end1 = time.time()\n",
        "    print(\"The duration of processing the data is :\", (end1-start) /60, \" Minutes\")\n",
        "\n",
        "    #Choose the model and create the CNN model\n",
        "    model                           = Models.choose_Model(Config.Current_CNN, Config.IMAGE_WIDTH,  Config.IMAGE_HEIGHT, Config.Num_Classes,Config.classifier)\n",
        "    EarlyStoppingMonitor            = EarlyStopping(patience=Config.epochs)\n",
        "\n",
        "    #Encode labels to one hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\n",
        "    y_train_onehot                  = CNN.One_Hot_Encoding(y_train, Config.Num_Classes)\n",
        "    y_test_onehot                   = CNN.One_Hot_Encoding(y_test , Config.Num_Classes)\n",
        "    y_val_onehot                    = CNN.One_Hot_Encoding(y_val  , Config.Num_Classes)\n",
        "\n",
        "    if Config.classifier ==\"softmax\":\n",
        "\n",
        "      model                       = Models.create_softmax_classifier(model, Config.Num_Classes)\n",
        "\n",
        "      if Config.augment:\n",
        "\n",
        "          train_generator, val_generator, test_generator = Data.Augment_x_train_flow(x_train, y_train_onehot, x_val, y_val,  x_test, y_test, Config.batch_size )\n",
        "          history     = model.fit(train_generator, epochs= Config.epochs, validation_data=val_generator, callbacks= [EarlyStoppingMonitor])\n",
        "          y_test      = np.argmax(y_test, axis=1)\n",
        "          CNN.evaluate_generator(model, history , test_generator, y_test, Config.Num_Classes, Config.CMT_labels, Config.batch_size, Config.IMAGE_WIDTH)\n",
        "\n",
        "      else:\n",
        "          history     = model.fit(x = x_train, y = y_train_onehot,validation_data= (x_val, y_val_onehot),epochs = Config.epochs, batch_size = Config.batch_size,callbacks = [EarlyStoppingMonitor],shuffle= False)\n",
        "          CNN.evaluate_x_test(model , history , x_test, y_test_onehot, Config.Num_Classes, Config.CMT_labels, Config.batch_size)\n",
        "\n",
        "    else:\n",
        "\n",
        "      Models.choose_classifier( x_train, y_train, x_test, y_test, Config.classifier,\n",
        "                               Config.IMAGE_WIDTH,  Config.IMAGE_HEIGHT, Config.optimizeParam,\n",
        "                               Config.optimizer, Config.CMT_labels, Config.Num_Classes)\n",
        "\n",
        "    end2 = time.time()\n",
        "    print(\"The duration of excuting this projct is :\", (end2-start) /60, \" Minutes\")\n",
        "\n",
        "    \"\"\" ******************************************************************************** \"\"\""
      ],
      "metadata": {
        "id": "9vYuziO3yab3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}